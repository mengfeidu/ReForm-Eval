# ReForm-Eval
An benchmark for evaluating the capabilities of large vision-language models (LVLMs). ReForm-Eval is constructed by re-formulating existing task-oriented multi-modal benchmarks. 

**We are in the process of preparing the data and code, and anticipate that it will be online within one week.**

